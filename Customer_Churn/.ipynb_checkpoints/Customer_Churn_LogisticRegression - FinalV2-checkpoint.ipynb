{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77f940a",
   "metadata": {},
   "source": [
    "---\n",
    "# Customer Churn Prediction \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d755bb6",
   "metadata": {},
   "source": [
    "| Column Name       | Description                                  | Data Type   |\n",
    "|-------------------|----------------------------------------------|-------------|\n",
    "| customerID        | Unique customer identifier                   | Object      |\n",
    "| gender            | Customer's gender (Male or Female)          | Object      |\n",
    "| SeniorCitizen     | Senior citizen status (1 for Yes, 0 for No) | Integer     |\n",
    "| Partner           | Whether the customer has a partner (Yes/No) | Object      |\n",
    "| Dependents        | Whether the customer has family members or dependents who are also using the same service or subscription (Yes/No)| Object      |\n",
    "| tenure            | Number of months customer stayed            | Integer     |\n",
    "| PhoneService      | Phone service status (Yes or No)            | Object      |\n",
    "| MultipleLines     | Multiple phone lines status (Yes/No/No svc) | Object      |\n",
    "| InternetService   | Internet service provider (DSL, Fiber, No)  | Object      |\n",
    "| OnlineSecurity    | Online security status (Yes/No/No svc)      | Object      |\n",
    "| OnlineBackup      | Online backup status (Yes/No/No svc)        | Object      |\n",
    "| DeviceProtection  | Device protection status (Yes/No/No svc)    | Object      |\n",
    "| TechSupport       | Tech support status (Yes/No/No svc)         | Object      |\n",
    "| StreamingTV       | Streaming TV status (Yes/No/No svc)         | Object      |\n",
    "| StreamingMovies   | Streaming movies status (Yes/No/No svc)     | Object      |\n",
    "| Contract          | Contract type (Month-to-month, 1 yr, 2 yr)  | Object      |\n",
    "| PaperlessBilling  | Paperless billing status (Yes/No)           | Object      |\n",
    "| PaymentMethod     | Payment method chosen by customer           | Object      |\n",
    "| MonthlyCharges    | Monthly charges incurred by the customer   | Float       |\n",
    "| TotalCharges      | Total charges incurred by the customer     | Object      |\n",
    "| Churn             | Churn status (Yes/No)...measure of customers leaving the business                        | Object      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568cf5a8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0005d602",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluation metrics  \u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score, precision_score, recall_score, r2_score   \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "# Linear algebra/numerical operations  \n",
    "import numpy as np\n",
    "# Visualization    \n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt     \n",
    "%matplotlib inline\n",
    "# For Machine or Deep Learning\n",
    "import tensorflow as tf\n",
    "# High-level api for tensorflow   \n",
    "from tensorflow import keras  \n",
    "# Pre-processing tool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "# Classifiers  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "# Evaluation metrics  \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, r2_score   \n",
    "from scipy.stats import randint, boxcox\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9575336",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_csv('telco_customer_churn.csv')\n",
    "cc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aef6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.isnull().sum()\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenure means the number of months the customer has stayed with the company\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=cc, x='tenure', hue='Churn', bins=30, kde=False, common_norm=False)\n",
    "\n",
    "plt.xlabel('Tenure (Number of Months)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Tenure by Churn')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf6ffe",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b594b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_numeric(cc['TotalCharges'])\n",
    "# ValueError: Unable to parse string \" \" at position 488\n",
    "pd.to_numeric(cc['TotalCharges'], errors = 'coerce') # It works but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...we got null values to deal with.\n",
    "print(\"Null values in TotalCharges:\", pd.to_numeric(cc['TotalCharges'], errors = 'coerce').isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc[pd.to_numeric(cc['TotalCharges'], errors = 'coerce').isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e045687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dtype of TotalCharges from string to integer/float \n",
    "cc.TotalCharges = pd.to_numeric(cc['TotalCharges'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling null values with mean of TotalCharges\n",
    "mean_value = cc['TotalCharges'].mean()\n",
    "cc['TotalCharges'].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b791bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.TotalCharges.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns\n",
    "cc.drop('customerID', axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729543fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b09b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.TotalCharges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483fc6d",
   "metadata": {},
   "source": [
    "### Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a07151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_summary(x):\n",
    "# UC = MEAN + 2 STD\n",
    "    uc = x.mean()+(2*x.std())\n",
    "    lc = x.mean()-(2*x.std())\n",
    "    \n",
    "    for i in x:\n",
    "        if i<lc or i>uc:\n",
    "            count = 1             # This means that column is having an OUTLier\n",
    "        else:\n",
    "            count = 0             # That column in not having an outliers\n",
    "            \n",
    "    outlier_flag = count\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),  x.std(), \n",
    "                      x.var(), x.min(), x.quantile(0.01), x.quantile(0.05),x.quantile(0.10),\n",
    "                      x.quantile(0.25),x.quantile(0.50),x.quantile(0.75), \n",
    "                      x.quantile(0.90),x.quantile(0.95), x.quantile(0.99),x.max() , \n",
    "                      lc , uc,outlier_flag],\n",
    "                  index=['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR', 'MIN', \n",
    "                         'P1' , 'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,\n",
    "                         'MAX','LC','UC','outlier_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899006dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc[numeric_columns].apply(lambda x: var_summary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ea0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cc['TotalCharges'], kde=True, bins = 10)\n",
    "plt.title('Histogram of TotalCharges')\n",
    "plt.xlabel('TotalCharges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e883b25",
   "metadata": {},
   "source": [
    "#### With Imputation \n",
    "Replacing the outliers in the 'TotalCharges' column with the mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtc = cc['TotalCharges'].median()\n",
    "# cc['TotalCharges'] = cc['TotalCharges'].apply(lambda x: mtc if abs(x) > 2 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a8ca8",
   "metadata": {},
   "source": [
    "#### Removing the Outliers (Not-Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bf021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Z-Score threshold for outliers (e.g., 2 or 3 standard deviations)\n",
    "# threshold = 2 \n",
    "# z_scores = stats.zscore(cc['TotalCharges'])\n",
    "# Create a new column with Z-Score values\n",
    "# cc['Z_Score'] = z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding rows with outliers\n",
    "# outlier_rows = cc[abs(z_scores) > threshold]\n",
    "# outlier_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = cc[abs(z_scores) <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82aec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.drop('Z_Score', axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614a7ea",
   "metadata": {},
   "source": [
    "#### Log Transformation \n",
    "Instead of imputing or removing outliers, we can also use log transformations to make our model less sensitive to extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d335cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to the feature with outliers\n",
    "# cc['TotalCharges'] = np.log1p(cc['TotalCharges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9d225",
   "metadata": {},
   "source": [
    "#### Winsorization (Recommended)\n",
    "Winsorization caps extreme values at a specified threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = cc['TotalCharges'].quantile(0.01)\n",
    "upper_bound = cc['TotalCharges'].quantile(0.99)\n",
    "cc['TotalCharges'] = cc['TotalCharges'].clip(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf6315",
   "metadata": {},
   "source": [
    "#### Box-Cox Transformation\n",
    "The Box-Cox transformation is a family of power transformations that includes logarithm (when the power is 0) and square root (when the power is 0.5) transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 to handle zero values\n",
    "# cc['TotalCharges_boxcox'], _ = boxcox(cc['TotalCharges'] + 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e87ce0",
   "metadata": {},
   "source": [
    "#### Square Root Transformation:\n",
    "Taking the square root is another option, particularly effective for data with moderate positive skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ebfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc['TotalCharges_sqrt'] = np.sqrt(cc['TotalCharges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc[numeric_columns].apply(lambda x: var_summary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52f31f",
   "metadata": {},
   "source": [
    "### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076207b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing unnescessary data \n",
    "for col in cc:\n",
    "    if cc[col].dtypes == 'object':\n",
    "        print(col ,cc[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83254fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.replace('No phone service', 'No', inplace = True)\n",
    "cc.replace('No internet service', 'No', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537672db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cc:\n",
    "    if cc[col].dtypes == 'object':\n",
    "        print(col ,cc[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bdc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store categorical columns containing 'Yes' and 'No'\n",
    "yes_no_cols = []\n",
    "for col in cc:\n",
    "    unique_cols = cc[col].unique()\n",
    "    if sorted(unique_cols) == ['No', 'Yes']:\n",
    "        yes_no_cols.append(col)\n",
    "\n",
    "print(yes_no_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing catcategorical data with binary values\n",
    "for col in yes_no_cols:\n",
    "    cc[col].replace({'Yes': 1, 'No': 0}, inplace=  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a752ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cc:\n",
    "    if cc[col].dtypes == 'object':\n",
    "        print(col ,cc[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc['gender'].replace({'Male': 0, 'Female': 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cc:\n",
    "    if cc[col].dtypes == 'object':\n",
    "        print(col ,cc[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fb8d1",
   "metadata": {},
   "source": [
    "If you have many categorical features or features with high cardinality (many unique values), this can lead to a significant increase in the number of columns and data size.\n",
    "\n",
    "Whereas for us, our cardinality is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1 = pd.get_dummies(data = cc, columns=['InternetService', 'Contract', 'PaymentMethod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510de1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding bool columns\n",
    "bool_cols = []\n",
    "for col in cc1:\n",
    "    if cc1[col].dtypes == 'bool':\n",
    "        bool_cols.append(col)\n",
    "\n",
    "print(bool_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4335aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting booleans into integer dtypes\n",
    "for col in bool_cols:\n",
    "    cc1[col] = cc1[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63071941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the remaining columns \n",
    "cols_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "scaler = MinMaxScaler()\n",
    "cc1[cols_to_scale] = scaler.fit_transform(cc1[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cc1:\n",
    "    print(col ,cc1[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf16910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix = cc1.corr()\n",
    "churn_correlations = correlation_matrix[\"Churn\"].sort_values(ascending=False)\n",
    "print(churn_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8421565",
   "metadata": {},
   "source": [
    "- A positive correlation (e.g., values close to 1) suggests that as the values in the other column increase, the likelihood of churn increases. For example, \"Contract_Month-to-month\" and \"InternetService_Fiber optic\" have positive correlations with churn, indicating that customers with month-to-month contracts or fiber optic internet service are more likely to churn.\n",
    "<br><br>\n",
    "- A negative correlation (e.g., values close to -1) suggests that as the values in the other column increase, the likelihood of churn decreases. For example, \"tenure\" has a negative correlation with churn, suggesting that customers with longer tenure are less likely to churn.\n",
    "<br><br>\n",
    "- Correlation values close to 0 indicate a weak linear relationship between the columns. For example, \"gender\" and \"PhoneService\" have correlation values close to 0, suggesting that these factors have little to no impact on churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = cc1.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604e4ec",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cc1.drop('Churn', axis = 'columns')\n",
    "y = cc1['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('SVM', SVC()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# Iterating through each model and performing cross-validation\n",
    "for name, model in models:\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f'{name}: Average accuracy: {scores.mean():.2f} (+/- {scores.std() * 2:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b2c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_state = 0\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Loop over random states from 0 to 99\n",
    "for state in range(201):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=state)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_state = state\n",
    "\n",
    "print(f'Best random state {model}: {best_state} with accuracy: {best_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best random state for GradientBoostingClassifier(): 158 with accuracy: 0.83\n",
    "# Best random state LogisticRegression(): 150 with accuracy: 0.82\n",
    "# Best random state SVC(): 35 with accuracy: 0.82\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5629b169",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for ele in yp:\n",
    "    if ele > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "        \n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how well your model fits the data.\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R²):\", round(r_squared,4)*10)\n",
    "print(\"R-squared (R²):\", round(r_squared,1)*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b747f83",
   "metadata": {},
   "source": [
    "Adjusted R² penalizes the inclusion of unnecessary predictors and provides a more realistic assessment of a model's fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139449c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y_test)  # Number of data points\n",
    "p = X_test.shape[1]  # Number of predictors (features)\n",
    "\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared (Adjusted R²):\", round(adjusted_r_squared,2)*10)\n",
    "print(\"Adjusted R-squared (Adjusted R²):\", round(adjusted_r_squared,1)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy,2)*100)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d129f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.math.confusion_matrix(labels = y_test, predictions= y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels = y_test, predictions= y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ce34e",
   "metadata": {},
   "source": [
    "- **True Positives (TP):** These are cases where the model correctly predicted the positive class. In our matrix, there are (approx) 200 true positives (bottom-right corner). These are customers who were correctly predicted to churn.\n",
    "<br><br>\n",
    "- **True Negatives (TN):** These are cases where the model correctly predicted the negative class. In our matrix, there are (approx) 967 true negatives (top-left corner). These are customers who were correctly predicted not to churn.\n",
    "<br><br>\n",
    "- **False Positives (FP):** These are cases where our model incorrectly predicted the positive class when it should have predicted the negative class. There are 66 false positives (top-right corner). These are customers who were incorrectly predicted to churn when they didn't (Type I error).\n",
    "<br><br>\n",
    "- **False Negatives (FN):** These are cases where the model incorrectly predicted the negative class when it should have predicted the positive class. There are 176 false negatives (bottom-left corner). These are customers who were incorrectly predicted not to churn when they did (Type II error).\n",
    "<br><br>\n",
    "Accuracy can be calculated as (TP + TN) / (TP + TN + FP + FN), and it represents the overall correctness of predictions. \n",
    "<br><br>\n",
    "So, in our case, accuracy would be approximately (200 + 967) / (200 + 967 + 66 + 176)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e216bc",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd16851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters of the model\n",
    "default_params = model.get_params()\n",
    "print(\"Default Parameters:\")\n",
    "for param, value in default_params.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': randint(10, 200),\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'max_features': [None]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier()\n",
    "# WE'll use RandomizedSearchCV for this problem\n",
    "# It's more efficient than grid search, especially when the search space is large.\n",
    "rand_search = RandomizedSearchCV(classifier, param_distributions=param_dist, n_iter=20, cv=3, \n",
    "                                 scoring='accuracy', random_state=best_state, n_jobs=-1)\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "best_params = rand_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rand_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on Test Set:\", round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cac7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels = y_test, predictions= y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
